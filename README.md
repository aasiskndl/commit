# Here it is like a daily memo what i have learnt 
## Aug 10, 2025
There are alot of rumors going on about AGI(Artificial General Intelligence) where a robot has a profound sense of knowledge like a human being. It can reason think and do the tasks efficiently resembling the astronomical human capabilities. But the thing is that we tend to underlook the scenario, how llm has a greater domain of knowledge than that of a singular human being, it can act like a thera[pist, a doctor, a competitive coder and what not. So, having an AGI will benefit us? Or will it be our greatest enemy is certainly the question to ask, what is an AGI goes out of control and behaves like a Chhiti the robot on a movie character played by Rajni Kant. In my opinion, its not the fear to be replaced by AI in some job, but its the fear that are we making something irreversal that will cause vast impact in human and industrial civilization like back in the days. We need to be prepared and know the uncertainties of these industries because they can throw anything at us at anytime.

## Aug 11, 2025
There are alot of things left to reasearch in the field of AI, but before sensing the AGI there are some of the works left in the field of large language models(LLM's) because they are prone to make some of mistakes. Back in the days, when gemini was initially launched it told one user to die out of fraustration. I dont know much of the context why was that harsh answer was concluded but it might be the issue when the data was being in the filtering process because most of the llm's are trained on the internet data like twitter, reddit posts and comments to know the sentence and grammatical structure in the first stage of the model training process. When the model was trained fully, in the filtering process some of the information got leaked out and if the context was releavent to some harsh texts, and lets assume that the were missed out on the filtering process then it comes out of llm. But LLM's has came a long way and they are not doing those mistakes bu there is 
